{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training of model based on optimized hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages and dataset\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "\n",
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/MLB/pitch_value')\n",
    "dataset = pd.read_csv('./data/datasets/cleaned_war_pitch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = dataset.drop(columns=[\"Unnamed: 0\", \"Name\", \"pitch_name\", \"description\", \"launch_angle\", \"launch_speed\", \"sz_top\", \"sz_bot\", \"WAR\"]).dropna(axis=0)\n",
    "y = X['estimated_woba']\n",
    "X = X.drop(columns=['estimated_woba'])\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=.1, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10586551  0.17400624  0.15825532 ...  0.17718679 -0.11977647\n",
      "  0.11714765]\n",
      "R-squared on Test Set: 0.2210806586877433\n",
      "Mean Squared Error on Test Set: 0.045955857648654605\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.9, device=None, early_stopping_rounds=3,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=39,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50000, n_jobs=-1,\n",
      "             num_parallel_tree=None, random_state=None, ...)\n",
      "Feature: called_strike, Importance: 0.452169269323349\n",
      "Feature: swinging_strike, Importance: 0.5111003518104553\n",
      "Feature: pitch_velo_adj, Importance: 0.001084000919945538\n",
      "Feature: horz_position_of_pitch, Importance: 0.0047422186471521854\n",
      "Feature: vertical_pos_of_pitch, Importance: 0.005105896852910519\n",
      "Feature: horz_release_pos, Importance: 0.000732377462554723\n",
      "Feature: vertical_release_pos, Importance: 0.0006732206675224006\n",
      "Feature: horz_movement, Importance: 0.0019226878648623824\n",
      "Feature: vertical_movement, Importance: 0.0013906193198636174\n",
      "Feature: velo_in_horz, Importance: 0.0010132240131497383\n",
      "Feature: velo_in_vert, Importance: 0.0016209367895498872\n",
      "Feature: ax, Importance: 0.0009753520716913044\n",
      "Feature: ay, Importance: 0.0007183413254097104\n",
      "Feature: az, Importance: 0.0032214042730629444\n",
      "Feature: release_spin, Importance: 0.0011314827715978026\n",
      "Feature: release_position, Importance: 0.000606261775828898\n",
      "Feature: spin_axis, Importance: 0.0008115266682580113\n",
      "Feature: in_strike_zone, Importance: 0.010980788618326187\n"
     ]
    }
   ],
   "source": [
    "# best para found after grid search\n",
    "opti_para = {'colsample_bytree': 0.9,\n",
    "             'learning_rate': 0.2, 'max_depth': 5,\n",
    "             'max_leaves': 39, 'min_child_weight': 6,\n",
    "             'subsample': 1}\n",
    "# model\n",
    "reg = xgb.XGBRegressor(**opti_para, n_jobs=-1, n_estimators=50000, early_stopping_rounds=3)\n",
    "reg.fit(train_x, train_y, eval_set=[(test_x, test_y)], verbose=False)\n",
    "\n",
    "# features / predictions\n",
    "feature_importances = reg.feature_importances_\n",
    "predictions = reg.predict(test_x)\n",
    "print(predictions)\n",
    "\n",
    "r2 = r2_score(test_y, predictions)\n",
    "print(\"R-squared on Test Set:\", r2)\n",
    "\n",
    "# results and feature importances\n",
    "print(\"Mean Squared Error on Test Set:\", mean_squared_error(test_y, predictions))\n",
    "print(reg)\n",
    "hasattr(train_x, 'columns')\n",
    "feature_names = train_x.columns\n",
    "for feature, importance in zip(feature_names, feature_importances):\n",
    "    print(f\"Feature: {feature}, Importance: {importance}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
