{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('C:/Users/dalto/OneDrive/Pictures/Documents/Projects/MLB/pitch_value')\n",
    "dataset = pd.read_csv('./data/datasets/yearly/cleaned_war_pitch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = dataset.drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\", \"Name\", \"pitch_name\", \"description\", \"launch_angle\", \"launch_speed\", \"sz_top\", \"sz_bot\",\"estimated_woba\"]).dropna(axis=0)\n",
    "y = X['WAR']\n",
    "X = X.drop(columns=['WAR'])\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=.1, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Name  True_WAR  Predicted_WAR\n",
      "259513       harrison, kyle  0.801637       0.699201\n",
      "655072       gausman, kevin  2.860714       1.430260\n",
      "204225        brieske, beau  0.719378       0.856517\n",
      "529547     crawford, kutter  1.858968       1.200945\n",
      "208627          mears, nick  0.772697       0.719613\n",
      "...                     ...       ...            ...\n",
      "271057     alexander, tyler -0.569328       0.616783\n",
      "481607          gray, sonny  3.837520       3.868281\n",
      "673560  yamamoto, yoshinobu  2.822026       2.610413\n",
      "575505        barlow, scott  0.038422       1.729190\n",
      "196039    kochanowicz, jack  0.612831       0.269415\n",
      "\n",
      "[64828 rows x 3 columns]\n",
      "R-squared on Test Set: 0.6279326375590716\n",
      "Mean Squared Error on Test Set: 0.7428089774765325\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.9, device=None, early_stopping_rounds=3,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=40, max_leaves=39,\n",
      "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50000, n_jobs=-1,\n",
      "             num_parallel_tree=None, random_state=None, ...)\n",
      "                   Feature  Importance\n",
      "0            called_strike    0.008962\n",
      "1          swinging_strike    0.021742\n",
      "2           pitch_velo_adj    0.070651\n",
      "3   horz_position_of_pitch    0.010721\n",
      "4    vertical_pos_of_pitch    0.013489\n",
      "5         horz_release_pos    0.117806\n",
      "6     vertical_release_pos    0.113125\n",
      "7            horz_movement    0.052847\n",
      "8        vertical_movement    0.056359\n",
      "9             velo_in_horz    0.023804\n",
      "10            velo_in_vert    0.080222\n",
      "11                      ax    0.054529\n",
      "12                      ay    0.017716\n",
      "13                      az    0.068555\n",
      "14            release_spin    0.086279\n",
      "15        release_position    0.103222\n",
      "16               spin_axis    0.094596\n",
      "17          in_strike_zone    0.005375\n"
     ]
    }
   ],
   "source": [
    "# best para found after grid search\n",
    "opti_para = {'colsample_bytree': 0.9,\n",
    "             'learning_rate': 0.05, 'max_depth': 40,\n",
    "             'max_leaves': 39, 'min_child_weight': 6,\n",
    "             'subsample': 1}\n",
    "# model\n",
    "reg = xgb.XGBRegressor(**opti_para, n_jobs=-1, n_estimators=50000, early_stopping_rounds=3)\n",
    "reg.fit(train_x, train_y, eval_set=[(test_x, test_y)], verbose=False)\n",
    "\n",
    "# features / predictions\n",
    "feature_importances = reg.feature_importances_\n",
    "predictions = reg.predict(test_x)\n",
    "# Attach predictions to true values and player names\n",
    "results_df = test_x.copy()\n",
    "results_df['True_WAR'] = test_y.values\n",
    "results_df['Predicted_WAR'] = predictions\n",
    "results_df['Name'] = dataset.loc[test_x.index, 'Name'].values\n",
    "\n",
    "print(results_df[['Name', 'True_WAR', 'Predicted_WAR']])\n",
    "\n",
    "r2 = r2_score(test_y, predictions)\n",
    "print(\"R-squared on Test Set:\", r2)\n",
    "\n",
    "# results and feature importances\n",
    "print(\"Mean Squared Error on Test Set:\", mean_squared_error(test_y, predictions))\n",
    "print(reg)\n",
    "hasattr(train_x, 'columns')\n",
    "feature_names = train_x.columns\n",
    "# Create a dataframe for feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "print(feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
